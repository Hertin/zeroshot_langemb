{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alleged-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import librosa\n",
    "import subprocess\n",
    "import shlex\n",
    "import torch\n",
    "import fairseq\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if 'cd' not in globals():\n",
    "    os.chdir('..')\n",
    "    cd = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "common-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "babel_langs=\"103 107 206 307 402 404 505\".split()\n",
    "babel_recog=\"101 203\".split()\n",
    "gp_langs=\"Czech French Mandarin Thai Bulgarian German Turkish Portuguese\".split()\n",
    "gp_recog=\"Spanish Polish Croatian\".split()\n",
    "\n",
    "symbol_dict = {}\n",
    "for babel_lang in babel_langs + babel_recog:\n",
    "    tr_dir = os.path.join('data', babel_lang, 'data', 'train_' + babel_lang, 'text')\n",
    "    dev_dir = os.path.join('data', babel_lang, 'data', 'dev_' + babel_lang, 'text')\n",
    "    eval_dir = os.path.join('data', babel_lang, 'data', 'eval_' + babel_lang, 'text')\n",
    "    \n",
    "    all_txt = []\n",
    "    for text_dir in [tr_dir, dev_dir, eval_dir]:\n",
    "        f = codecs.open(text_dir).readlines()\n",
    "        for line in f:\n",
    "            true_text = line.split(maxsplit = 1)\n",
    "            if len(true_text) != 1:\n",
    "                true_text = true_text[1].replace('\\n','')\n",
    "                if '<' in true_text:\n",
    "                    print(babel_lang)\n",
    "                    print('Damn!')\n",
    "                    print(true_text)\n",
    "                all_txt.append(true_text)\n",
    "            \n",
    "    all_txt = ''.join(all_txt)\n",
    "    labels = list(set(all_txt))\n",
    "    \n",
    "    symbol_dict[babel_lang] = sorted(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "synthetic-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for gp_lang in gp_langs + gp_recog:\n",
    "    tr_dir = os.path.join('data', 'GlobalPhone/gp_' + gp_lang + '_train', 'text')\n",
    "    dev_dir = os.path.join('data', 'GlobalPhone/gp_' + gp_lang + '_dev', 'text')\n",
    "    eval_dir = os.path.join('data', 'GlobalPhone/gp_' + gp_lang + '_eval', 'text')\n",
    "    \n",
    "    all_txt = []\n",
    "    for text_dir in [tr_dir, dev_dir, eval_dir]:\n",
    "        f = codecs.open(text_dir).readlines()\n",
    "        for line in f:\n",
    "            true_text = line.split(maxsplit = 1)[1].replace('\\n','')\n",
    "            if '<' in true_text:\n",
    "                print('Damn!')\n",
    "                print(true_text)\n",
    "            all_txt.append(true_text)\n",
    "            \n",
    "    all_txt = ''.join(all_txt)\n",
    "    labels = list(set(all_txt))\n",
    "    \n",
    "    symbol_dict[gp_lang] = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "'103', '107', '206', '307', '402', '404', 'BG', 'CH', 'CZ', 'FR', 'GE', 'N', 'PO', 'TH', 'TU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "military-distribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " dict_keys(['103', '107', '206', '307', '402', '404', '505', '101', '203', 'Czech', 'French', 'Mandarin', 'Thai', 'Bulgarian', 'German', 'Turkish', 'Portuguese', 'Spanish', 'Polish', 'Croatian']))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbol_dict),  symbol_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "international-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2ll = {\n",
    "    '103': '103', \n",
    "    '107': '107',\n",
    "    '206': '206',\n",
    "    '307': '307',\n",
    "    '402': '402',\n",
    "    '404': '404',\n",
    "    '101': '101',\n",
    "    '203': '203',\n",
    "    'Bulgarian': 'BG',\n",
    "    'Mandarin': 'CH',\n",
    "    'Czech': 'CZ',\n",
    "    'Croatian': 'CR',\n",
    "    'French': 'FR',\n",
    "    'German': 'GE',\n",
    "    '505': 'N',\n",
    "    'Polish': 'PL',\n",
    "    'Portuguese': 'PO',\n",
    "    'Spanish': 'SP',\n",
    "    'Thai': 'TH',\n",
    "    'Turkish': 'TU'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "specialized-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang2ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "applied-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2ph = {}\n",
    "for l, ph in symbol_dict.items():\n",
    "    ll = lang2ll[l]\n",
    "    lang2ph[ll] = [p for p in ph if p != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "english-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('phones/lang2ph.json', 'w') as f:\n",
    "    json.dump(lang2ph, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-notice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
