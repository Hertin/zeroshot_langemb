{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "global-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "if 'cd' not in globals():\n",
    "    cd = True\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limiting-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cer(plot_dir):\n",
    "    data = []\n",
    "    for folder in os.listdir(plot_dir):\n",
    "            if folder.startswith('snapshot.ep.'):\n",
    "                ep = int(folder.strip('snapshot.ep.'))\n",
    "                with open(f'{plot_dir}/{folder}/result.txt', 'r', encoding=\"utf-8\") as f:\n",
    "                    for l in f:\n",
    "                        if 'Sum/Avg' in l:\n",
    "                            pter = float(l.strip().strip('|').strip().split()[-2])\n",
    "                            data.append((ep, pter))\n",
    "                            break\n",
    "\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "    eps, pters = zip(*data)\n",
    "    return np.array(eps), np.array(pters)\n",
    "\n",
    "def get_cer_with_cache(plot_dir, cache_data):\n",
    "    if plot_dir in cache_data:\n",
    "        eps, pters = cache_data[plot_dir]\n",
    "    else:\n",
    "        eps, pters = get_cer(plot_dir)\n",
    "        cache_data[plot_dir] = eps, pters\n",
    "    return eps, pters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excellent-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "recog_langs = ['Spanish', 'Polish', 'Croatian', '203', '101']\n",
    "fake_lang_labels = ['CR', 'PL', 'SP', 'PO', 'TU', 'GE', 'BG', 'TH', 'CH', 'FR', 'CZ', '203', '101', 'N', '404', '402', '307', '206', '107', '103']\n",
    "langs = ['Croatian', 'Polish', 'Spanish', 'Portuguese', 'Turkish', 'German', 'Bulgarian', 'Thai', 'Mandarin', 'French', 'Czech', '203', '101', '505', '404', '402', '307', '206', '107', '103']\n",
    "lang_labels = ['CR', 'PL', 'SP', 'PO', 'TU', 'GE', 'BG', 'TH', 'CH', 'FR', 'CZ', '203', '101', 'N', '404', '402', '307', '206', '107', '103']\n",
    "train_langs = ['Portuguese', 'Turkish', 'German', 'Bulgarian', 'Thai', 'Mandarin', 'French', 'Czech', '505', '404', '402', '307', '206', '107', '103']\n",
    "lang2label = {lang: label for lang, label in zip(langs, lang_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-astronomy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dimensional-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opening-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f270e38411440558c7fd9f9c2510a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='i_recog_lang', max=4), Output()), _dom_classes=('widget-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def update(i_recog_lang=(0,len(recog_langs)-1)):\n",
    "    recog_lang = recog_langs[i_recog_lang]\n",
    "    ll = lang2label[recog_lang]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for tag in ['wav2vecfexlemb', 'wav2vecfexlembglottoonly', 'wav2vecfexlembphonly']:\n",
    "        plot_dir = f'exp/train_pytorch_{tag}/plot_mask_eval_{recog_lang}_{ll}_decode'\n",
    "\n",
    "        eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "\n",
    "        plt.plot(eps, pters, label=f'{recog_lang}_{ll}_{tag}')\n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "italian-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vecfexlemb \tSpanish SP 34.4\n",
      "wav2vecfexlemb \tPolish PL 54.0\n",
      "wav2vecfexlemb \tCroatian CR 35.2\n",
      "wav2vecfexlemb \t203 203 72.8\n",
      "wav2vecfexlemb \t101 101 73.1\n",
      "mean 53.9\n",
      "wav2vecfexlembglottoonly \tSpanish SP 34.8\n",
      "wav2vecfexlembglottoonly \tPolish PL 55.7\n",
      "wav2vecfexlembglottoonly \tCroatian CR 35.1\n",
      "wav2vecfexlembglottoonly \t203 203 69.5\n",
      "wav2vecfexlembglottoonly \t101 101 73.4\n",
      "mean 53.7\n",
      "wav2vecfexlembphonly \tSpanish SP 38.8\n",
      "wav2vecfexlembphonly \tPolish PL 53.4\n",
      "wav2vecfexlembphonly \tCroatian CR 36.6\n",
      "wav2vecfexlembphonly \t203 203 76.0\n",
      "wav2vecfexlembphonly \t101 101 71.9\n",
      "mean 55.339999999999996\n"
     ]
    }
   ],
   "source": [
    "ep = 29\n",
    "for tag in ['wav2vecfexlemb', 'wav2vecfexlembglottoonly', 'wav2vecfexlembphonly']:\n",
    "    test_pters = []\n",
    "    for recog_lang in recog_langs:\n",
    "        ll = lang2label[recog_lang]\n",
    "        plot_dir = f'exp/train_pytorch_{tag}/plot_mask_eval_{recog_lang}_{ll}_decode'\n",
    "\n",
    "        eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "        print(f'{tag} \\t{recog_lang} {ll} {pters[ep]}')\n",
    "        test_pters.append(pters[ep])\n",
    "    print(f'mean {np.mean(test_pters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-neighbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "preceding-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav2vecfexlemb \tSpanish SP 37.3\n",
      "wav2vecfexlemb \tPolish PL 59.8\n",
      "wav2vecfexlemb \tCroatian CR 41.3\n",
      "wav2vecfexlemb \t203 203 76.3\n",
      "wav2vecfexlemb \t101 101 74.6\n",
      "mean 57.85999999999999\n",
      "wav2vecfexlembglottoonly \tSpanish SP 37.1\n",
      "wav2vecfexlembglottoonly \tPolish PL 59.7\n",
      "wav2vecfexlembglottoonly \tCroatian CR 42.4\n",
      "wav2vecfexlembglottoonly \t203 203 73.0\n",
      "wav2vecfexlembglottoonly \t101 101 76.2\n",
      "mean 57.68000000000001\n",
      "wav2vecfexlembphonly \tSpanish SP 46.7\n",
      "wav2vecfexlembphonly \tPolish PL 57.8\n",
      "wav2vecfexlembphonly \tCroatian CR 46.0\n",
      "wav2vecfexlembphonly \t203 203 77.7\n",
      "wav2vecfexlembphonly \t101 101 73.5\n",
      "mean 60.339999999999996\n"
     ]
    }
   ],
   "source": [
    "ep = 29\n",
    "for tag in ['wav2vecfexlemb', 'wav2vecfexlembglottoonly', 'wav2vecfexlembphonly']:\n",
    "    test_pters = []\n",
    "    for recog_lang in recog_langs:\n",
    "        ll = lang2label[recog_lang]\n",
    "        plot_dir = f'exp/train_pytorch_{tag}/plot_eval_{recog_lang}_{ll}_decode'\n",
    "\n",
    "        eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "        print(f'{tag} \\t{recog_lang} {ll} {pters[ep]}')\n",
    "        test_pters.append(pters[ep])\n",
    "    print(f'mean {np.mean(test_pters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-needle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def update(i_recog_lang=(0,len(recog_langs)-1), others=True):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 30\n",
    "# fake_lang_labels=['CR']\n",
    "@interact\n",
    "def update(i_recog_lang=(0,len(recog_langs)-1), others=True):\n",
    "    recog_lang = recog_langs[i_recog_lang]\n",
    "    print(recog_lang)\n",
    "    plt.figure(figsize=(20,12))\n",
    "#     if others:\n",
    "    for ii, fll in enumerate(fake_lang_labels):\n",
    "        plot_dir = f'exp/train_pytorch_wav2vecfexlemb/plot_eval_{recog_lang}_{fll}_decode'\n",
    "        if not os.path.exists(plot_dir):\n",
    "            continue\n",
    "        eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "        alpha = 0 if not others and fll != lang2label[recog_lang] else 1\n",
    "        plt.plot(eps, pters, label=f'{recog_lang}_'+fll, alpha=alpha)\n",
    "        min_ep = eps[np.argmin(pters)]\n",
    "        if others:\n",
    "            plt.text(eps[ii%max_epoch], pters[ii%max_epoch], f'{fll}')\n",
    "\n",
    "    # baseline\n",
    "    ll = lang2label[recog_lang]\n",
    "    plot_dir = f'exp/train_pytorch_wav2vecfex/plot_eval_{recog_lang}_{ll}_decode'\n",
    "#     if os.path.exists(plot_dir):\n",
    "        \n",
    "    eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "    plt.plot(eps, pters, label=f'{recog_lang}_base', linestyle='--')\n",
    "    \n",
    "    plot_dir = f'exp/train_pytorch_wav2vecfex/plot_mask_eval_{recog_lang}_{ll}_decode'\n",
    "       \n",
    "    eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "    plt.plot(eps, pters, label=f'{recog_lang}_basemask', linestyle='--')\n",
    "\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
