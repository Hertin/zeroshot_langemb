{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interpreted-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "remarkable-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from espnet.asr.pytorch_backend.asr import load_trained_model\n",
    "if 'cd' not in globals():\n",
    "    cd = True\n",
    "    os.chdir('..')\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "labeled-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cer(plot_dir):\n",
    "    data = []\n",
    "    for folder in os.listdir(plot_dir):\n",
    "            if folder.startswith('snapshot.ep.'):\n",
    "                ep = int(folder.strip('snapshot.ep.'))\n",
    "                with open(f'{plot_dir}/{folder}/result.txt', 'r', encoding=\"utf-8\") as f:\n",
    "                    for l in f:\n",
    "                        if 'Sum/Avg' in l:\n",
    "                            pter = float(l.strip().strip('|').strip().split()[-2])\n",
    "                            data.append((ep, pter))\n",
    "                            break\n",
    "\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "    eps, pters = zip(*data)\n",
    "    return np.array(eps), np.array(pters)\n",
    "\n",
    "def get_cer_with_cache(plot_dir, cache_data):\n",
    "    if plot_dir in cache_data:\n",
    "        eps, pters = cache_data[plot_dir]\n",
    "    else:\n",
    "        eps, pters = get_cer(plot_dir)\n",
    "        cache_data[plot_dir] = eps, pters\n",
    "    return eps, pters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "higher-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_data = {}\n",
    "langs = ['Croatian', 'Polish', 'Spanish', 'Portuguese', 'Turkish', 'German', 'Bulgarian', 'Thai', 'Mandarin', 'French', 'Czech', '203', '101', '505', '404', '402', '307', '206', '107', '103']\n",
    "lang_labels = ['CR', 'PL', 'SP', 'PO', 'TU', 'GE', 'BG', 'TH', 'CH', 'FR', 'CZ', '203', '101', 'N', '404', '402', '307', '206', '107', '103']\n",
    "train_langs = ['Portuguese', 'Turkish', 'German', 'Bulgarian', 'Thai', 'Mandarin', 'French', 'Czech', '505', '404', '402', '307', '206', '107', '103']\n",
    "lang2label = {lang: label for lang, label in zip(langs, lang_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch=30\n",
    "test_langs = ['Croatian', 'Polish', 'Spanish', '203', '101'] + train_langs\n",
    "chosen_ep = 29\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(test_langs)))\n",
    "# plt.figure(figsize=(20,15))\n",
    "cross_pters = []\n",
    "for i, lang in enumerate(test_langs):\n",
    "    label = lang2label[lang]\n",
    "    plot_dir = f'exp/train_pytorch_wav2vecfexlembft/plot_mask_eval_{lang}_{label}_decode'\n",
    "#     base_plot_dir = f'exp/train_pytorch_wav2vecfexlembadv/plot_eval_{lang}_{label}_decode'\n",
    "#     if not os.path.exists(base_plot_dir): \n",
    "#         continue\n",
    "    eps, pters = get_cer_with_cache(plot_dir, cache_data)\n",
    "#     plt.plot(eps[:max_epoch], pters[:max_epoch], label=f'{lang}_'+label, color=colors[i])\n",
    "    min_ep = eps[np.argmin(pters)]\n",
    "    min_pter = min(pters)\n",
    "#     print(f'lgcn Lang: {lang} min_ep: {min_ep} min_pter {min_pter}')\n",
    "    print(f'lemb  Lang: {lang} ep: {min_ep} min_pter {min_pter}')\n",
    "\n",
    "#     print(f'base Lang: {lang} min_ep: {min_ep} min_pter {min_pter}')\n",
    "print(','.join(test_langs))\n",
    "print(','.join(cross_pters))\n",
    "# plt.legend()\n",
    "# plt.title(f'LGCN MASK PTER {eps[chosen_ep]}')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-process",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recreational-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:reading model parameters from exp/train_pytorch_wav2vecfexlembft/results/snapshot.ep.14\n",
      "WARNING:root:idim 512\n",
      "WARNING:root:do not fix feature extractor\n",
      "WARNING:root:LangEmb All langs ['101', '103', '107', '203', '206', '307', '402', '404', 'BG', 'CH', 'CR', 'CZ', 'FR', 'GE', 'N', 'PL', 'PO', 'SP', 'TH', 'TU']\n",
      "WARNING:root:Use all features\n",
      "WARNING:root:load g2v npy directly\n",
      "WARNING:root:lang_indices  [1935, 8033, 511, 12196, 13877, 6815, 1340, 657, 5768, 3605, 11307, 5749, 15682, 12835, 9753, 3743, 15536, 14894, 12194, 2867]\n",
      "WARNING:root:n2v_embedding  (20, 256)\n",
      "WARNING:root:lang embedding size torch.Size([20, 425])\n",
      "WARNING:root:warpctc_length_average False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "continued-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:reading model parameters from exp/train_pytorch_wav2vecfexlembft/results/snapshot.ep.14\n",
      "WARNING:root:idim 512\n",
      "WARNING:root:do not fix feature extractor\n",
      "WARNING:root:LangEmb All langs ['101', '103', '107', '203', '206', '307', '402', '404', 'BG', 'CH', 'CR', 'CZ', 'FR', 'GE', 'N', 'PL', 'PO', 'SP', 'TH', 'TU']\n",
      "WARNING:root:Use all features\n",
      "WARNING:root:load g2v npy directly\n",
      "WARNING:root:lang_indices  [1935, 8033, 511, 12196, 13877, 6815, 1340, 657, 5768, 3605, 11307, 5749, 15682, 12835, 9753, 3743, 15536, 14894, 12194, 2867]\n",
      "WARNING:root:n2v_embedding  (20, 256)\n",
      "WARNING:root:lang embedding size torch.Size([20, 425])\n",
      "WARNING:root:warpctc_length_average False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.0.weight Parameter containing:\n",
      "tensor([[[-9.9304e-02, -3.9093e-02,  1.5503e-01,  ...,  2.1631e-01,\n",
      "           2.3183e-02,  2.7759e-01]],\n",
      "\n",
      "        [[ 9.3201e-02, -8.4900e-02, -2.8931e-01,  ..., -1.4417e-01,\n",
      "           1.9194e-02,  2.4133e-01]],\n",
      "\n",
      "        [[ 1.2659e-01, -2.5732e-01,  2.1460e-01,  ..., -2.2522e-01,\n",
      "           2.9663e-01, -1.2927e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1680e-01, -6.2347e-02,  1.5552e-01,  ..., -2.3279e-01,\n",
      "           1.7435e-05,  4.0747e-01]],\n",
      "\n",
      "        [[-1.8237e-01, -1.4844e-01,  7.2083e-02,  ...,  8.0994e-02,\n",
      "           2.2376e-02,  2.8076e-01]],\n",
      "\n",
      "        [[ 2.4622e-01,  1.3763e-02, -1.2627e-02,  ..., -9.3427e-03,\n",
      "           1.4844e-01,  1.7493e-01]]], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "i = 14\n",
    "model, train_args = load_trained_model(f'exp/train_pytorch_wav2vecfexlembft/results/snapshot.ep.{i}')\n",
    "device = torch.device('cuda:1')\n",
    "model = model.float()\n",
    "model1 = model.to(device)\n",
    "for n, p in model1.feature_extractor.named_parameters():\n",
    "    print(n, p)\n",
    "    p1 = p\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ahead-rover",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:reading model parameters from exp/train_pytorch_wav2vecfexlembglottoonly/results/snapshot.ep.30\n",
      "WARNING:root:idim 512\n",
      "WARNING:root:fix feature extractor\n",
      "WARNING:root:LangEmb All langs ['101', '103', '107', '203', '206', '307', '402', '404', 'BG', 'CH', 'CR', 'CZ', 'FR', 'GE', 'N', 'PL', 'PO', 'SP', 'TH', 'TU']\n",
      "WARNING:root:Use glotto features\n",
      "WARNING:root:load g2v npy directly\n",
      "WARNING:root:lang_indices  [1935, 8033, 511, 12196, 13877, 6815, 1340, 657, 5768, 3605, 11307, 5749, 15682, 12835, 9753, 3743, 15536, 14894, 12194, 2867]\n",
      "WARNING:root:n2v_embedding  (20, 256)\n",
      "WARNING:root:lang embedding size torch.Size([20, 256])\n",
      "WARNING:root:warpctc_length_average False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.0.weight Parameter containing:\n",
      "tensor([[[-9.9304e-02, -3.9093e-02,  1.5503e-01,  ...,  2.1631e-01,\n",
      "           2.3178e-02,  2.7759e-01]],\n",
      "\n",
      "        [[ 9.3201e-02, -8.4900e-02, -2.8931e-01,  ..., -1.4417e-01,\n",
      "           1.9196e-02,  2.4133e-01]],\n",
      "\n",
      "        [[ 1.2659e-01, -2.5732e-01,  2.1460e-01,  ..., -2.2522e-01,\n",
      "           2.9663e-01, -1.2927e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1680e-01, -6.2347e-02,  1.5552e-01,  ..., -2.3279e-01,\n",
      "           2.6882e-05,  4.0747e-01]],\n",
      "\n",
      "        [[-1.8237e-01, -1.4844e-01,  7.2083e-02,  ...,  8.0994e-02,\n",
      "           2.2385e-02,  2.8076e-01]],\n",
      "\n",
      "        [[ 2.4622e-01,  1.3771e-02, -1.2619e-02,  ..., -9.3384e-03,\n",
      "           1.4844e-01,  1.7493e-01]]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "i = 30\n",
    "model, train_args = load_trained_model(f'exp/train_pytorch_wav2vecfexlembglottoonly/results/snapshot.ep.{i}')\n",
    "device = torch.device('cuda:1')\n",
    "model = model.float()\n",
    "model = model.to(device)\n",
    "for n, p in model.feature_extractor.named_parameters():\n",
    "    print(n, p)\n",
    "    p2 = p\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "second-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:reading model parameters from exp/train_pytorch_wav2vecfexlembglottoonly/results/snapshot.ep.14\n",
      "WARNING:root:idim 512\n",
      "WARNING:root:fix feature extractor\n",
      "WARNING:root:LangEmb All langs ['101', '103', '107', '203', '206', '307', '402', '404', 'BG', 'CH', 'CR', 'CZ', 'FR', 'GE', 'N', 'PL', 'PO', 'SP', 'TH', 'TU']\n",
      "WARNING:root:Use glotto features\n",
      "WARNING:root:load g2v npy directly\n",
      "WARNING:root:lang_indices  [1935, 8033, 511, 12196, 13877, 6815, 1340, 657, 5768, 3605, 11307, 5749, 15682, 12835, 9753, 3743, 15536, 14894, 12194, 2867]\n",
      "WARNING:root:n2v_embedding  (20, 256)\n",
      "WARNING:root:lang embedding size torch.Size([20, 256])\n",
      "WARNING:root:warpctc_length_average False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.0.weight Parameter containing:\n",
      "tensor([[[-9.9304e-02, -3.9093e-02,  1.5503e-01,  ...,  2.1631e-01,\n",
      "           2.3178e-02,  2.7759e-01]],\n",
      "\n",
      "        [[ 9.3201e-02, -8.4900e-02, -2.8931e-01,  ..., -1.4417e-01,\n",
      "           1.9196e-02,  2.4133e-01]],\n",
      "\n",
      "        [[ 1.2659e-01, -2.5732e-01,  2.1460e-01,  ..., -2.2522e-01,\n",
      "           2.9663e-01, -1.2927e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1680e-01, -6.2347e-02,  1.5552e-01,  ..., -2.3279e-01,\n",
      "           2.6882e-05,  4.0747e-01]],\n",
      "\n",
      "        [[-1.8237e-01, -1.4844e-01,  7.2083e-02,  ...,  8.0994e-02,\n",
      "           2.2385e-02,  2.8076e-01]],\n",
      "\n",
      "        [[ 2.4622e-01,  1.3771e-02, -1.2619e-02,  ..., -9.3384e-03,\n",
      "           1.4844e-01,  1.7493e-01]]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "i = 14\n",
    "model, train_args = load_trained_model(f'exp/train_pytorch_wav2vecfexlembglottoonly/results/snapshot.ep.{i}')\n",
    "device = torch.device('cuda:1')\n",
    "model = model.float()\n",
    "model3 = model.to(device)\n",
    "\n",
    "for n, p in model3.feature_extractor.named_parameters():\n",
    "    print(n, p)\n",
    "    p3 = p\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "metropolitan-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(p1 == p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "quiet-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-9.9304e-02, -3.9093e-02,  1.5503e-01,  ...,  2.1631e-01,\n",
       "           2.3183e-02,  2.7759e-01]],\n",
       "\n",
       "        [[ 9.3201e-02, -8.4900e-02, -2.8931e-01,  ..., -1.4417e-01,\n",
       "           1.9194e-02,  2.4133e-01]],\n",
       "\n",
       "        [[ 1.2659e-01, -2.5732e-01,  2.1460e-01,  ..., -2.2522e-01,\n",
       "           2.9663e-01, -1.2927e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.1680e-01, -6.2347e-02,  1.5552e-01,  ..., -2.3279e-01,\n",
       "           1.7435e-05,  4.0747e-01]],\n",
       "\n",
       "        [[-1.8237e-01, -1.4844e-01,  7.2083e-02,  ...,  8.0994e-02,\n",
       "           2.2376e-02,  2.8076e-01]],\n",
       "\n",
       "        [[ 2.4622e-01,  1.3763e-02, -1.2627e-02,  ..., -9.3427e-03,\n",
       "           1.4844e-01,  1.7493e-01]]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fossil-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-9.9304e-02, -3.9093e-02,  1.5503e-01,  ...,  2.1631e-01,\n",
       "           2.3178e-02,  2.7759e-01]],\n",
       "\n",
       "        [[ 9.3201e-02, -8.4900e-02, -2.8931e-01,  ..., -1.4417e-01,\n",
       "           1.9196e-02,  2.4133e-01]],\n",
       "\n",
       "        [[ 1.2659e-01, -2.5732e-01,  2.1460e-01,  ..., -2.2522e-01,\n",
       "           2.9663e-01, -1.2927e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.1680e-01, -6.2347e-02,  1.5552e-01,  ..., -2.3279e-01,\n",
       "           2.6882e-05,  4.0747e-01]],\n",
       "\n",
       "        [[-1.8237e-01, -1.4844e-01,  7.2083e-02,  ...,  8.0994e-02,\n",
       "           2.2385e-02,  2.8076e-01]],\n",
       "\n",
       "        [[ 2.4622e-01,  1.3771e-02, -1.2619e-02,  ..., -9.3384e-03,\n",
       "           1.4844e-01,  1.7493e-01]]], device='cuda:1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sunset-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n",
      "tensor(False, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for (n1, p1), (n3, p3) in zip(model1.feature_extractor.named_parameters(), model3.feature_extractor.named_parameters()):\n",
    "    print(torch.all(p1==p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
